{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "c85c4f45-723f-5a49-aea4-cd15d3ece1d4",
        "openai_ephemeral_user_id": "e3080733-f1cb-509a-bf33-e5463097e58b",
        "openai_subdivision1_iso_code": "IN-KA"
      }
    },
    "noteable": {
      "last_transaction_id": "aa33bb89-0f02-49c8-a004-74eb8c2b1df5"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "171734d8-561d-49b3-bc2d-8b31d5e23c35",
      "cell_type": "markdown",
      "source": "# Emotion Recognition using EEG Brainwave Data\n\n## Project Overview\n\nIn this project, I aim to predict human emotions using EEG brainwave data. EEG (Electroencephalography) is a technique used to record electrical activity in the brain. The dataset I'm using contains EEG readings from individuals experiencing different emotions, and my goal is to build a machine learning model that can accurately predict the emotion based on these readings.\n\n## Dataset\n\nThe dataset I'm using is available on Kaggle and contains EEG brainwave data along with the associated emotion for each data point. The emotions are categorized into three classes: POSITIVE, NEUTRAL, and NEGATIVE. The EEG data is represented as various features derived from the EEG signals, such as mean and FFT (Fast Fourier Transform) values.\n\n## Approach\n\nI start by preprocessing the data, which involves cleaning, normalization, and splitting the data into a training set and a test set. I then train a Random Forest model on the training data and evaluate its performance on the test data. I also explore other models like Logistic Regression and Gradient Boosting, and perform hyperparameter tuning and cross-validation to improve the performance of my models.\n\nThroughout the project, I also visualize the data and the results to gain a better understanding of the relationships between the features and the target variable. This includes creating a correlation heatmap, a feature importance plot, and a confusion matrix.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "30481348-7b31-4ea3-830e-5d11fa30883a",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "779c5a2a-7bbc-4c7b-897c-6d04d724c6d7"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T07:33:35.205571+00:00",
          "start_time": "2023-06-25T07:33:29.292515+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install kaggle",
      "outputs": []
    },
    {
      "id": "cdba9566-ee1d-4ba8-8e48-c504b27d5269",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "7f78aa82-d42d-420b-98ed-f6f17a68bceb"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T07:33:48.826234+00:00",
          "start_time": "2023-06-25T07:33:48.670401+00:00"
        }
      },
      "execution_count": null,
      "source": "import os\nos.environ['KAGGLE_USERNAME'] = 'vasanthdesai2020'\nos.environ['KAGGLE_KEY'] = 'abe1a7dbf0a92f3136ea7a7913106542'",
      "outputs": []
    },
    {
      "id": "9c82e52e-dabd-4c2f-84ed-21f9548fdb0f",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "6abf7915-b73b-4fda-bcec-ec88c212acb8"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T07:33:59.753620+00:00",
          "start_time": "2023-06-25T07:33:58.216461+00:00"
        }
      },
      "execution_count": null,
      "source": "!kaggle datasets download -d birdy654/eeg-brainwave-dataset-feeling-emotions",
      "outputs": []
    },
    {
      "id": "74911505-76cd-416d-808e-a49bf3df732c",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "62e46d9a-fe60-4d15-a45c-ea0ce2077343"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T07:34:12.982376+00:00",
          "start_time": "2023-06-25T07:34:11.923004+00:00"
        }
      },
      "execution_count": null,
      "source": "!unzip eeg-brainwave-dataset-feeling-emotions.zip",
      "outputs": []
    },
    {
      "id": "8720e01e-151b-46b3-8168-a6ba4edb6355",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "9b1b6582-5192-411b-8bf5-3a4eee260c8d"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T13:39:08.304915+00:00",
          "start_time": "2023-06-25T13:39:00.005027+00:00"
        },
        "datalink": {
          "6e716e6b-bc82-4c5f-b5b3-2e858ba15e18": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 2549,
              "orig_num_rows": 5,
              "orig_size_bytes": 102000,
              "truncated_num_cols": 100,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 4040,
              "truncated_string_columns": []
            },
            "display_id": "6e716e6b-bc82-4c5f-b5b3-2e858ba15e18",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-25T07:34:39.613340",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_f2c2ed8caab446219feeac2d07f86c6e"
          },
          "7c5086c0-6798-41af-a4ee-1751ea7dbb8e": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 2549,
              "orig_num_rows": 5,
              "orig_size_bytes": 102000,
              "truncated_num_cols": 100,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 4040,
              "truncated_string_columns": []
            },
            "display_id": "7c5086c0-6798-41af-a4ee-1751ea7dbb8e",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-25T13:39:07.646605",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_9856d62c99ce45f3a0b5f6aab0c7db24"
          }
        }
      },
      "execution_count": null,
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('emotions.csv')\ndf.head()",
      "outputs": []
    },
    {
      "id": "4704ffee-8096-4a21-9960-faa3824eee3d",
      "cell_type": "markdown",
      "source": "## Data Exploration\n\nBefore I proceed with any kind of model training, it's important for me to understand the nature of our data. Let's start by checking the shape of our dataset, the number of unique labels (emotions), and the distribution of these labels.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "70d3f4a0-4259-4233-aeab-1d1c95d57db0",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "9c6c265b-ff7a-4f64-9087-f9804f07205f"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T13:44:39.070801+00:00",
          "start_time": "2023-06-25T13:44:38.477015+00:00"
        }
      },
      "execution_count": null,
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Print dataset shape\nprint(f'\\033[1;34mDataset shape: {df.shape}\\033[0m')\n\n# Print unique labels\nprint(f'\\033[1;36mUnique labels: {df.label.unique()}\\033[0m')\n\n# Print label distribution\nprint(f'\\033[1;32mLabel distribution:\\033[0m\\n{df.label.value_counts()}')\n\n# Plot the distribution of labels/emotions\nplt.figure(figsize=(10, 5))\nsns.countplot(x='label', data=df, palette=\"cool\")\nplt.title('Emotion Distribution', color='purple')\nplt.grid(color = 'gray', linestyle = '--', linewidth = 0.5)\nplt.show()\n",
      "outputs": []
    },
    {
      "id": "002d10de-9a37-4921-af87-27df55a79a58",
      "cell_type": "markdown",
      "source": "## Data Preprocessing\n\nNow that we have a basic understanding of our data, let's preprocess it for our machine learning models. This involves the following steps:\n\n1. **Label Encoding:** Convert the categorical target labels (emotions) into numerical values.\n2. **Feature Scaling:** Standardize the features to have a mean of 0 and a standard deviation of 1. This is important for many machine learning models and helps improve their performance.\n3. **Train-Test Split:** Split the data into a training set and a test set. The training set is used to train the model, and the test set is used to evaluate its performance.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "95538a6d-72a6-45c0-aec8-650d915dc8c3",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "7c41b4e4-149b-4435-84f5-1af8ec9227a2"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T13:48:04.046037+00:00",
          "start_time": "2023-06-25T13:48:03.745736+00:00"
        }
      },
      "execution_count": null,
      "source": "from sklearn.preprocessing import LabelEncoder\n\n# Label encoding\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['label'])\n\n# Feature scaling\nscaler = StandardScaler()\nfeatures = df.drop('label', axis=1)\nscaled_features = scaler.fit_transform(features)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(scaled_features, df['label'], test_size=0.2, random_state=42)\n\nX_train.shape, X_test.shape",
      "outputs": []
    },
    {
      "id": "e9ca3408-092b-4287-9993-42ba608828da",
      "cell_type": "markdown",
      "source": "## Model Training and Evaluation\n\nWe're now ready to train our machine learning model. We'll start with a Random Forest classifier, which is a powerful and versatile machine learning model that works well on a wide range of datasets.\n\nAfter training the model, we'll evaluate its performance on the test set. We'll look at the accuracy of the model, as well as the confusion matrix, which shows the number of correct and incorrect predictions for each class.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "bbce6856-0d16-4370-a093-f19b33fd05c4",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f19ed2ba-1608-4cc6-9b25-9e0a4b242dee"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T13:48:18.269209+00:00",
          "start_time": "2023-06-25T13:48:13.289903+00:00"
        }
      },
      "execution_count": null,
      "source": "# Model training\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train, y_train)\n\n# Model evaluation\ny_pred = rf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)\n\nprint(f'Accuracy: {accuracy}')\nprint(f'Confusion Matrix:\\n{cm}')\n\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.show()",
      "outputs": []
    },
    {
      "id": "dabd7fbe-352b-483f-b2d4-7f32cbe8f47f",
      "cell_type": "markdown",
      "source": "## Feature Importance\n\nOne of the advantages of the Random Forest model is that it provides a straightforward way to examine the importance of each feature in making predictions. This can be useful for understanding which features are most influential in our model, and can also help guide further feature selection or engineering efforts.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "a2181a71-2c3d-47f7-b63c-d5697a23a522",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f7ef3f04-4cc1-4490-906b-cb9eb98a984b"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T13:49:51.796864+00:00",
          "start_time": "2023-06-25T13:49:51.051447+00:00"
        },
        "scrolled": false
      },
      "execution_count": null,
      "source": "feature_importances = rf.feature_importances_\nimportance_df = pd.DataFrame({'feature': features.columns, 'importance': feature_importances})\ntop_features = importance_df.sort_values('importance', ascending=False).head(20)\n\nplt.figure(figsize=(10, 8))\nsns.barplot(x='importance', y='feature', data=top_features, orient='h', color='#6096B4')\nplt.title('Top 20 Important Features')\nplt.show()",
      "outputs": []
    },
    {
      "id": "49bc3b86-fdce-4e5b-8c30-250814f238f2",
      "cell_type": "markdown",
      "source": "## Hyperparameter Tuning and Cross-Validation\n\nTo further improve the performance of our model, we can tune its hyperparameters. Hyperparameters are the parameters of the model that are not learned from the data, but are set beforehand. For the Random Forest model, these include the number of trees in the forest (n_estimators) and the maximum depth of the trees (max_depth), among others.\n\nWe'll use GridSearchCV from scikit-learn to perform a grid search over a range of possible hyperparameter values. GridSearchCV also performs cross-validation, which means it splits the training data into k 'folds' and trains and evaluates the model k times, each time with a different fold held out as a validation set. This provides a more robust estimate of the model's performance.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "99423975-a8b3-4315-8e29-28d403c05d06",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "10d6ce8a-11f7-48fd-8835-b305e2269e07"
        },
        "ExecuteTime": {
          "end_time": "2023-06-25T07:57:30.972098+00:00",
          "start_time": "2023-06-25T07:37:19.466583+00:00"
        }
      },
      "execution_count": null,
      "source": "# Hyperparameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10]\n}\n\n# Grid search\ngrid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Best parameters and score\nprint(f'Best parameters: {grid_search.best_params_}')\nprint(f'Best score: {grid_search.best_score_}')",
      "outputs": []
    },
    {
      "id": "c0330cac-b85f-467b-8700-2fe8d382441c",
      "cell_type": "markdown",
      "source": "We used EEG data to predict emotions, preprocesseding and splitting it into training and test sets. We trained a Random Forest model, evaluated its performance, explored feature importance, and tuned hyperparameters for optimization. \n\nThe optimal parameters resulted in approximately 98.4% accuracy on the cross-validation set, showing potential for accurate emotion prediction via EEG data, although real-world scenarios would be more complex. \n\nThis technology could advance mental health treatments, enhance tech interfaces, and contribute to neuroscience research, highlighting machine learning's potential in emotion recognition.\n",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    }
  ]
}